{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"PlasticDetection.pkl\")\n",
    "\n",
    "# Define the function to process each frame from the camera\n",
    "def process_frame(frame):\n",
    "    # Preprocess the frame\n",
    "    frame = cv2.resize(frame, (100, 100))\n",
    "    frame = frame.reshape(1, -1)\n",
    "    frame = frame.astype('float32') / 255\n",
    "\n",
    "    # Predict the label of the frame\n",
    "    label = model.predict(frame)\n",
    "\n",
    "    # Draw a rectangle and label on the frame indicating the prediction\n",
    "    if label[0] == \"plastic\":\n",
    "        cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Plastic\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Not Plastic\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Set the IP address and port number of the camera stream on your mobile device\n",
    "ip_address = '192.168.0.103'\n",
    "port_number = '8080'\n",
    "\n",
    "# Set the URL for the camera stream using the IP address and port number\n",
    "url = f'http://{ip_address}:{port_number}/video'\n",
    "\n",
    "# Open the mobile camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.open(url)\n",
    "\n",
    "# Loop through the frames from the camera and process each frame\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Process the frame\n",
    "    processed_frame = process_frame(frame)\n",
    "\n",
    "    # Display the processed frame\n",
    "    cv2.imshow('frame', processed_frame)\n",
    "\n",
    "    # Check for user input to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3948\\2395257871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Read a frame from the camera stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mimg_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nanin\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nanin\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('PlasticDetection.pkl')\n",
    "\n",
    "# Set the URL of the IP Webcam app on your mobile phone\n",
    "url = 'http://192.168.0.103:8080/video'\n",
    "\n",
    "# Open the camera stream\n",
    "stream = urllib.request.urlopen(url)\n",
    "\n",
    "# Loop through the frames in the camera stream\n",
    "while True:\n",
    "    # Read a frame from the camera stream\n",
    "    img_bytes = stream.read()\n",
    "    img_array = np.array(bytearray(img_bytes), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, -1)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    img = img.astype('float32') / 255\n",
    "    img = img.reshape(1, -1)\n",
    "    \n",
    "    # Make a prediction with the model\n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    # Display the result\n",
    "    if prediction == 'plastic':\n",
    "        print('Plastic detected!')\n",
    "    else:\n",
    "        print('Not plastic.')\n",
    "        \n",
    "    # Wait for a key press and exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera stream\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import winsound\n",
    "cam = cv2.VideoCapture(1)\n",
    "while cam.isOpened():\n",
    "    ret, frame1 = cam.read()\n",
    "    ret, frame2 = cam.read()\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) < 5000:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        winsound.PlaySound('alert.wav', winsound.SND_ASYNC)\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "    cv2.imshow('GrannyÂ Cam',frame1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectangle frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "# Load the SVM model from the pickle file\n",
    "model = load('PlasticDetection.pkl')\n",
    "\n",
    "# Define the boundaries of the plastic bottle (in RGB color space)\n",
    "lower = np.array([100, 100, 100])\n",
    "upper = np.array([255, 255, 255])\n",
    "\n",
    "# Create a VideoCapture object to read from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame from BGR to RGB color space\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Apply the color threshold to extract the plastic bottle regions\n",
    "    mask = cv2.inRange(frame_rgb, lower, upper)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Make predictions for each detected region\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        roi_resized = cv2.resize(roi, (100, 100))\n",
    "        roi_flattened = roi_resized.reshape(1, -1).astype('float32') / 255\n",
    "        prediction = model.predict(roi_flattened)\n",
    "        \n",
    "        # Draw a rectangle around the detected plastic bottle and label it as \"Plastic\" or \"Non-Plastic\"\n",
    "        if prediction == 'Plastic':\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Plastic', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "    \n",
    "    # Display the frame with the detected regions and predictions\n",
    "    cv2.imshow('Plastic Detection', frame)\n",
    "    \n",
    "    # Exit the program if the user presses the 'q' key\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['Non Plastic']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "\n",
    "# Load the saved SVM model\n",
    "model = joblib.load('PlasticDetection.pkl')\n",
    "\n",
    "# Set the webcam source\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capture an image from the webcam\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Resize the image to 100x100\n",
    "resized_frame = cv2.resize(frame, (100, 100))\n",
    "\n",
    "# Flatten the image and normalize the pixel values\n",
    "flattened_frame = resized_frame.reshape(1, -1).astype('float32') / 255\n",
    "\n",
    "# Pass the image through the model for prediction\n",
    "prediction = model.predict(flattened_frame)\n",
    "\n",
    "# Draw a bounding box around the detected plastic bottle\n",
    "if prediction == 'plastic':\n",
    "    cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 255, 0), thickness=2)\n",
    "\n",
    "# Display the image and the predicted label\n",
    "cv2.imwrite('test.jpg',frame)\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "cv2.imshow(str(prediction), image)\n",
    "print('Prediction:', prediction)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Release the webcam source and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Set the webcam source\n",
    "cap = cv2.VideoCapture(1)\n",
    "model = joblib.load('PlasticDetection.pkl')\n",
    "\n",
    "# Capture an image from the webcam\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Release the webcam source\n",
    "cap.release()\n",
    "\n",
    "# Save the captured image to a file\n",
    "cv2.imwrite('captured_image.jpg', frame)\n",
    "\n",
    "# Display the captured image\n",
    "cv2.imshow('image', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QR code Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrcode\n",
    "\n",
    "reward_amount = 3000\n",
    "\n",
    "qr = qrcode.QRCode(version=1, box_size=10, border=5)\n",
    "data = {'Amount':reward_amount,'Id':1}\n",
    "qr.add_data(data)\n",
    "qr.make(fit=True)\n",
    "img = qr.make_image(fill_color='black', back_color='white')\n",
    "img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan QR code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amount': 3000, 'Id': 1}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    d = cv2.QRCodeDetector()\n",
    "    val,c,f=d.detectAndDecode(frame)\n",
    "\n",
    "    cv2.imshow('QR Code Scanner', frame)\n",
    "\n",
    "    if val:\n",
    "        print(val)\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
